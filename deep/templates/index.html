<!DOCTYPE html>
<html>
<head>
    <title>Deep Cube</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta content="text/html;charset=utf-8" http-equiv="Content-Type">
	<meta content="utf-8" http-equiv="encoding">

    <!-- Bootstrap -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="/static/main.css">

    <!--[if lt IE 9]>
          <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
          <script src="//cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.min.js"></script>
		  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <![endif]-->

</head>
<body>
    <div class="container">
        <center>
            <h3>魔方辅助学习系统</h3>
            <div>
            <a href="/index/guidance">
            <button id="scramble" type="button">帮我还原手中魔方</button>
            </a>
            </div>
                 <br />
            <div>
            <a href="/index/challenge">
            <button id="solve" type="button">我要挑战魔方还原</button>
            </a>
            </div>
        </center>
    </div>
    <br>

    <br>
    <div class="well well-lg">
        <center>
        <a href="https://codeocean.com/capsule/5723040/">Source Code</a>
        <br>
        <br>
        <span style='color:black'>If you find this research useful to your work, please cite the following papers:</span><br><br>

        <span class="paper-title"><a href="https://www.nature.com/articles/s42256-019-0070-z.epdf?shared_access_token=-pCSsZa_J9bM8VyXLZLRctRgN0jAjWel9jnR3ZoTv0Osb8UCgUm5AQaSCMHWqWzsyV3KBcb13SAW-9IL1pAGd1HcSk40JSEjhoaBAi0ePvYh_5Dul6LvK0oJY1KI0ULo9O9HCut_y7aCTc93Th8m5g%3D%3D">Solving the Rubik's Cube with Deep Reinforcement Learning and Search</a></span><br>
        <span class="paper-authors">Forest Agostinelli*, Stephen McAleer*, Alexander Shmakov*, Pierre Baldi</span><br>
        <span class="paper-journal"><i>Nature Machine Intelligence</i>, Volume 1</span>,
        <span class="paper-year">2019</span>
        <br>
        <br>
        <span class="paper-title"><a href="https://openreview.net/pdf?id=Hyfn2jCcKm">Solving the Rubik's Cube with Approximate Policy Iteration</a></span><br>
        <span class="paper-authors">Stephen McAleer*, Forest Agostinelli*, Alexander Shmakov*, Pierre Baldi</span><br>
        <span class="paper-journal"><i>In Proceedings of the 7th International Conference on Learning Representations (ICLR)</i></span>,
        <span class="paper-year">2019</span>
        </center>
    </div>


<!--    <script src="/static/jquery.min.js"></script>-->
<!--    <script src="/static/main.js"></script>-->

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>z
    <script src="//cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script>


</body>
</html>
